{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the japanese phone dictionary \n",
    "def load_phone_dict(path):\n",
    "  phone_dict = list()\n",
    "  with open(path, 'r') as f:\n",
    "    for line in f:\n",
    "      phone_dict.append(line.strip())\n",
    "  return phone_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_to_one_hot(phone, phone_dict):\n",
    "  tmp = list(np.zeros(len(phone_dict)))\n",
    "  if phone=='None':   \n",
    "    return tmp\n",
    "  else:\n",
    "    tmp[phone_dict.index(phone)] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frame(time, window_size, step_size):\n",
    "  number_frames = np.round(time/step_size)+1\n",
    "  if number_frames >= 0:\n",
    "    return number_frames\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### convert /mono/.labs to csv\n",
    "#### a floder under /mono/ called /csv/ will be created and it will hold all the csv files with current, next, before\n",
    "#### the format of one example will be shown below\n",
    "\n",
    "# label_path = '/Users/ShiyuMu/Desktop/HTS-demo_NIT-SONG070-F001/data/labels/mono/'\n",
    "label_path = '/Users/ShiyuMu/Downloads/coldplay_dataset/txt/'\n",
    "fileList = [label_path + f for f in os.listdir(label_path) if f.endswith('.txt')]\n",
    "# fileList = [label_path + f for f in os.listdir(label_path) if f.endswith('.lab')]\n",
    "try:\n",
    "  # create dictionary to hold all the csv file \n",
    "  os.mkdir(label_path + 'csv/');\n",
    "  print('csv dictionary created')\n",
    "except:\n",
    "  pass\n",
    "for file in fileList:\n",
    "  df = pd.read_csv(file, sep=\" \", header=None)\n",
    "  df.columns = [\"beg\", \"end\", \"current\"]\n",
    "  df['before'] = pd.Series(['None']).append(df['current']).reset_index(drop=True)\n",
    "  df['next'] = df['current'][1:].append(pd.Series(['None'])).reset_index(drop=True)\n",
    "  df.to_csv(label_path + 'csv/'+ file.split('/')[-1]+'.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ShiyuMu/Downloads/coldplay_dataset/txt/coldplay_song02_04.txt'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load demision\n",
    "dimension_dict = dict()\n",
    "dimension_file = open('dimensions.txt', 'r')\n",
    "for line in dimension_file:\n",
    "  dimension_dict[line.strip().split()[0].strip('.npy')] = line.strip().split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of loading csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the path we just created\n",
    "csv_path = label_path + 'csv/'\n",
    "# get all csv files \n",
    "csvList = [csv_path + f for f in os.listdir(csv_path) if f.endswith('.csv')]\n",
    "df_list = list()\n",
    "## add all csv files as dataframe to a list\n",
    "for file in csvList:\n",
    "  df = pd.read_csv(file, sep='\\t')\n",
    "  df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the df_list contains 31 dataframe (since we have 31 dataset)\n",
    "## one dataframe will look like this. beg and end here indicates nonoseconds\n",
    "second_to_nano = 10000000\n",
    "# second_to_nano = 100000000\n",
    "df_list[0].head()\n",
    "for i in range(len(df_list)):\n",
    "  \n",
    "  df_list[i]['beg'] = df_list[i]['beg']*second_to_nano\n",
    "  df_list[i]['end'] = df_list[i]['end']*second_to_nano\n",
    "  df_list[i].beg = df_list[i].beg.astype(int)\n",
    "  df_list[i].end = df_list[i].end.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips_ids = [\"004\", \"007\", \"037\", \"010\", \"004\", \"004\", \"004\", \"004\"]\n",
    "# durations = [(1.1, 2.2), (6.5, 7.8), (5.4, 6.8), (15.6, 16.8), (12.0, 13.2), (17.9, 19.0), (21.9, 22.7), (26.4, 27.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>current</th>\n",
       "      <th>before</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18100000</td>\n",
       "      <td>20800000</td>\n",
       "      <td>er</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20800000</td>\n",
       "      <td>22599999</td>\n",
       "      <td>n</td>\n",
       "      <td>er</td>\n",
       "      <td>iy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22599999</td>\n",
       "      <td>27599999</td>\n",
       "      <td>iy</td>\n",
       "      <td>n</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27599999</td>\n",
       "      <td>27700000</td>\n",
       "      <td>th</td>\n",
       "      <td>iy</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27700000</td>\n",
       "      <td>29373242</td>\n",
       "      <td>pau</td>\n",
       "      <td>th</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beg       end current before  next\n",
       "14  18100000  20800000      er      d     n\n",
       "15  20800000  22599999       n     er    iy\n",
       "16  22599999  27599999      iy      n    th\n",
       "17  27599999  27700000      th     iy   pau\n",
       "18  27700000  29373242     pau     th  None"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[10].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load phoneme dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create phoneme dictionary list\n",
    "dict_set = set()\n",
    "for f in fileList:\n",
    "  file = open(f, 'r')\n",
    "  for line in file:\n",
    "    dict_set.add(line.strip().split()[-1])\n",
    "  file.close()\n",
    "list(dict_set)\n",
    "dict_file = open('english_dict.txt', 'w')\n",
    "for phone in list(dict_set):\n",
    "  dict_file.write(phone)\n",
    "  dict_file.write('\\n')\n",
    "dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(dict_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_dict_path = 'english_dict.txt'\n",
    "phone_dict = load_phone_dict(phone_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert timestamps to frame numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define window size and step size to convert timestamp to frame id\n",
    "window_size = 250000\n",
    "step_size = 50000\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "  df = df_list[i]\n",
    "  df_index = i\n",
    "#   print(csvList[df_index].split('/')[-1].rstrip('.txt.csv'))\n",
    "  df_name = csvList[df_index].split('/')[-1].rstrip('.txt.csv')\n",
    "  total_num_frames = int(dimension_dict[df_name])\n",
    "#   print(total_num_frames)\n",
    "  total_time = list(df['end'])[-1]\n",
    "#   total_num_frames = time_to_frame(total_time, window_size, step_size)\n",
    "#   print(len(df['beg'].values))\n",
    "  for index in range(len(df['beg'].values)):\n",
    "#     print(index)\n",
    "    df['beg'].values[index] = np.floor(df['beg'].values[index]/total_time*total_num_frames)\n",
    "#     df['beg'].values[index] = int(df['beg'].values[index]/total_time*total_num_frames)\n",
    "#     df['beg'].values[index] = time_to_frame(df['beg'].values[index], window_size, step_size)\n",
    "  for index in range(len(df['end'].values)):\n",
    "#     print(index)\n",
    "    df['end'].values[index] = np.floor(df['end'].values[index]/total_time*total_num_frames)\n",
    "#     df['end'].values[index] = int(df['end'].values[index]/total_time*total_num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>current</th>\n",
       "      <th>before</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>pau</td>\n",
       "      <td>None</td>\n",
       "      <td>ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>236</td>\n",
       "      <td>ay</td>\n",
       "      <td>pau</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236</td>\n",
       "      <td>238</td>\n",
       "      <td>pau</td>\n",
       "      <td>ay</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238</td>\n",
       "      <td>240</td>\n",
       "      <td>y</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>242</td>\n",
       "      <td>uw</td>\n",
       "      <td>y</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>242</td>\n",
       "      <td>262</td>\n",
       "      <td>z</td>\n",
       "      <td>uw</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>262</td>\n",
       "      <td>272</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>274</td>\n",
       "      <td>pau</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>274</td>\n",
       "      <td>294</td>\n",
       "      <td>t</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294</td>\n",
       "      <td>612</td>\n",
       "      <td>uw</td>\n",
       "      <td>t</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>612</td>\n",
       "      <td>824</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>824</td>\n",
       "      <td>826</td>\n",
       "      <td>r</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>826</td>\n",
       "      <td>827</td>\n",
       "      <td>uw</td>\n",
       "      <td>r</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>827</td>\n",
       "      <td>830</td>\n",
       "      <td>l</td>\n",
       "      <td>uw</td>\n",
       "      <td>dh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>830</td>\n",
       "      <td>832</td>\n",
       "      <td>dh</td>\n",
       "      <td>l</td>\n",
       "      <td>ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>832</td>\n",
       "      <td>834</td>\n",
       "      <td>ah</td>\n",
       "      <td>dh</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>834</td>\n",
       "      <td>836</td>\n",
       "      <td>w</td>\n",
       "      <td>ah</td>\n",
       "      <td>er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>836</td>\n",
       "      <td>838</td>\n",
       "      <td>er</td>\n",
       "      <td>w</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>838</td>\n",
       "      <td>840</td>\n",
       "      <td>l</td>\n",
       "      <td>er</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>840</td>\n",
       "      <td>864</td>\n",
       "      <td>d</td>\n",
       "      <td>l</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>864</td>\n",
       "      <td>914</td>\n",
       "      <td>pau</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>914</td>\n",
       "      <td>952</td>\n",
       "      <td>s</td>\n",
       "      <td>pau</td>\n",
       "      <td>iy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>952</td>\n",
       "      <td>994</td>\n",
       "      <td>iy</td>\n",
       "      <td>s</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>994</td>\n",
       "      <td>1014</td>\n",
       "      <td>z</td>\n",
       "      <td>iy</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1014</td>\n",
       "      <td>1034</td>\n",
       "      <td>pau</td>\n",
       "      <td>z</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1034</td>\n",
       "      <td>1036</td>\n",
       "      <td>w</td>\n",
       "      <td>pau</td>\n",
       "      <td>uh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1036</td>\n",
       "      <td>1038</td>\n",
       "      <td>uh</td>\n",
       "      <td>w</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1038</td>\n",
       "      <td>1054</td>\n",
       "      <td>d</td>\n",
       "      <td>uh</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1054</td>\n",
       "      <td>1082</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "      <td>ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1082</td>\n",
       "      <td>1130</td>\n",
       "      <td>ay</td>\n",
       "      <td>r</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2038</td>\n",
       "      <td>2039</td>\n",
       "      <td>n</td>\n",
       "      <td>ow</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2039</td>\n",
       "      <td>2292</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2292</td>\n",
       "      <td>2326</td>\n",
       "      <td>s</td>\n",
       "      <td>pau</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2326</td>\n",
       "      <td>2346</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>iy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2346</td>\n",
       "      <td>2372</td>\n",
       "      <td>iy</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2372</td>\n",
       "      <td>2388</td>\n",
       "      <td>p</td>\n",
       "      <td>iy</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2388</td>\n",
       "      <td>2394</td>\n",
       "      <td>pau</td>\n",
       "      <td>p</td>\n",
       "      <td>dh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2394</td>\n",
       "      <td>2408</td>\n",
       "      <td>dh</td>\n",
       "      <td>pau</td>\n",
       "      <td>ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2408</td>\n",
       "      <td>2424</td>\n",
       "      <td>ah</td>\n",
       "      <td>dh</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2424</td>\n",
       "      <td>2424</td>\n",
       "      <td>pau</td>\n",
       "      <td>ah</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2424</td>\n",
       "      <td>2442</td>\n",
       "      <td>s</td>\n",
       "      <td>pau</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2442</td>\n",
       "      <td>2464</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2464</td>\n",
       "      <td>2482</td>\n",
       "      <td>r</td>\n",
       "      <td>t</td>\n",
       "      <td>iy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2482</td>\n",
       "      <td>2512</td>\n",
       "      <td>iy</td>\n",
       "      <td>r</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2512</td>\n",
       "      <td>2530</td>\n",
       "      <td>t</td>\n",
       "      <td>iy</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2530</td>\n",
       "      <td>2560</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "      <td>pau</td>\n",
       "      <td>s</td>\n",
       "      <td>ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2560</td>\n",
       "      <td>2620</td>\n",
       "      <td>ay</td>\n",
       "      <td>pau</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2620</td>\n",
       "      <td>2622</td>\n",
       "      <td>pau</td>\n",
       "      <td>ay</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2622</td>\n",
       "      <td>2662</td>\n",
       "      <td>y</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2662</td>\n",
       "      <td>2670</td>\n",
       "      <td>uw</td>\n",
       "      <td>y</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2670</td>\n",
       "      <td>2702</td>\n",
       "      <td>z</td>\n",
       "      <td>uw</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2702</td>\n",
       "      <td>2712</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2712</td>\n",
       "      <td>2714</td>\n",
       "      <td>pau</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2714</td>\n",
       "      <td>2732</td>\n",
       "      <td>t</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2732</td>\n",
       "      <td>2934</td>\n",
       "      <td>uw</td>\n",
       "      <td>t</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2934</td>\n",
       "      <td>3038</td>\n",
       "      <td>pau</td>\n",
       "      <td>uw</td>\n",
       "      <td>ow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3038</td>\n",
       "      <td>3040</td>\n",
       "      <td>ow</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3040</td>\n",
       "      <td>3042</td>\n",
       "      <td>n</td>\n",
       "      <td>ow</td>\n",
       "      <td>pau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3042</td>\n",
       "      <td>3200</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      beg   end current before  next\n",
       "0       0   148     pau   None    ay\n",
       "1     148   236      ay    pau   pau\n",
       "2     236   238     pau     ay     y\n",
       "3     238   240       y    pau    uw\n",
       "4     240   242      uw      y     z\n",
       "5     242   262       z     uw     d\n",
       "6     262   272       d      z   pau\n",
       "7     272   274     pau      d     t\n",
       "8     274   294       t    pau    uw\n",
       "9     294   612      uw      t   pau\n",
       "10    612   824     pau     uw     r\n",
       "11    824   826       r    pau    uw\n",
       "12    826   827      uw      r     l\n",
       "13    827   830       l     uw    dh\n",
       "14    830   832      dh      l    ah\n",
       "15    832   834      ah     dh     w\n",
       "16    834   836       w     ah    er\n",
       "17    836   838      er      w     l\n",
       "18    838   840       l     er     d\n",
       "19    840   864       d      l   pau\n",
       "20    864   914     pau      d     s\n",
       "21    914   952       s    pau    iy\n",
       "22    952   994      iy      s     z\n",
       "23    994  1014       z     iy   pau\n",
       "24   1014  1034     pau      z     w\n",
       "25   1034  1036       w    pau    uh\n",
       "26   1036  1038      uh      w     d\n",
       "27   1038  1054       d     uh     r\n",
       "28   1054  1082       r      d    ay\n",
       "29   1082  1130      ay      r     z\n",
       "..    ...   ...     ...    ...   ...\n",
       "73   2038  2039       n     ow   pau\n",
       "74   2039  2292     pau      n     s\n",
       "75   2292  2326       s    pau     w\n",
       "76   2326  2346       w      s    iy\n",
       "77   2346  2372      iy      w     p\n",
       "78   2372  2388       p     iy   pau\n",
       "79   2388  2394     pau      p    dh\n",
       "80   2394  2408      dh    pau    ah\n",
       "81   2408  2424      ah     dh   pau\n",
       "82   2424  2424     pau     ah     s\n",
       "83   2424  2442       s    pau     t\n",
       "84   2442  2464       t      s     r\n",
       "85   2464  2482       r      t    iy\n",
       "86   2482  2512      iy      r     t\n",
       "87   2512  2530       t     iy     s\n",
       "88   2530  2560       s      t   pau\n",
       "89   2560  2560     pau      s    ay\n",
       "90   2560  2620      ay    pau   pau\n",
       "91   2620  2622     pau     ay     y\n",
       "92   2622  2662       y    pau    uw\n",
       "93   2662  2670      uw      y     z\n",
       "94   2670  2702       z     uw     d\n",
       "95   2702  2712       d      z   pau\n",
       "96   2712  2714     pau      d     t\n",
       "97   2714  2732       t    pau    uw\n",
       "98   2732  2934      uw      t   pau\n",
       "99   2934  3038     pau     uw    ow\n",
       "100  3038  3040      ow    pau     n\n",
       "101  3040  3042       n     ow   pau\n",
       "102  3042  3200     pau      n  None\n",
       "\n",
       "[103 rows x 5 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now df_list contains 31 dataframe, one would be like this\n",
    "\n",
    "df_list[-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfold all frames and list them one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corase_encoding(current_index, beg, end):\n",
    "  middle = int((end-beg)/2)\n",
    "  if current_index == beg:\n",
    "    return [1, 0, 0]\n",
    "  elif current_index == middle:\n",
    "    return [0, 1, 0]\n",
    "  elif current_index == end:\n",
    "    return [0, 0, 1]\n",
    "  else:\n",
    "    inverse_dist_beg = 1/np.abs(current_index-beg)\n",
    "    inverse_dist_middle = 1/np.abs(current_index-middle)\n",
    "    inverse_dist_end = 1/np.abs(current_index-end)\n",
    "    p_beg = inverse_dist_beg/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    p_middle = inverse_dist_middle/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    p_end = inverse_dist_end/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    return [p_beg, p_middle, p_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_df_list = list()\n",
    "for dataset in df_list:\n",
    "  unfold_list = list()\n",
    "  for index in range(dataset.shape[0]):\n",
    "#     print(index)\n",
    "    beg_ = int(dataset.iloc[index]['beg'] + 1)\n",
    "    end_ = int(dataset.iloc[index]['end'])\n",
    "#     print(end_)\n",
    "    current_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['current'], phone_dict))\n",
    "    before_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['before'], phone_dict))\n",
    "    next_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['next'], phone_dict))\n",
    "    corase_encoding_vectors = np.asarray(corase_encoding(index, beg_, end_))\n",
    "#     print(corase_encoding_vectors)\n",
    "\n",
    "\n",
    "    if index == 0:\n",
    "      for i in range(beg_, end_+1):  \n",
    "        unfold_list.append([beg_, end_, np.asarray(phone_to_one_hot('None', phone_dict)), current_, next_, corase_encoding(i, beg_, end_)])\n",
    "    elif index == (dataset.shape[0] -1):\n",
    "      for i in range(beg_, end_+1):  \n",
    "        unfold_list.append([beg_, end_, before_, current_, np.asarray(phone_to_one_hot('None', phone_dict)), corase_encoding(i, beg_, end_)])\n",
    "    else:\n",
    "      for i in range(beg_, end_+1):  \n",
    "        unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(i, beg_, end_)])      \n",
    "      \n",
    "#     if index == 0:\n",
    "#       unfold_list.append([beg_, end_, np.asarray(phone_to_one_hot('None', phone_dict)), current_, next_, corase_encoding(beg_, beg_, end_)])\n",
    "#     else:\n",
    "#       unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(beg_, beg_, end_)])\n",
    "#       for i in range(beg_+1, end_):\n",
    "#         unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(i, beg_, end_)])\n",
    "#       if index == (dataset.shape[0] -1):\n",
    "#         unfold_list.append([beg_, end_, before_, current_, np.asarray(phone_to_one_hot('None', phone_dict)), corase_encoding(end_, beg_, end_)])\n",
    "#       else:\n",
    "#         unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(end_, beg_, end_)])\n",
    "      \n",
    "  unfold_df = pd.DataFrame(unfold_list, columns=['beg', 'end', 'before', 'current', 'next', 'coarse'])\n",
    "  unfolded_df_list.append(unfold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 6)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded_df_list[-10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_folder(folder_name):\n",
    "  try:  \n",
    "    os.mkdir(folder_name);\n",
    "#     print('folder created: ', folder_name)\n",
    "  except:\n",
    "#     print('folder already exist: ', folder_name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coldplay_song06_04\n",
      "(1047,)\n",
      "coldplay_song07_02\n",
      "(3930,)\n",
      "coldplay_song05_01\n",
      "(6123,)\n",
      "coldplay_song01_06\n",
      "(4232,)\n",
      "coldplay_song03_04\n",
      "(5963,)\n",
      "coldplay_song06_05\n",
      "(4436,)\n",
      "coldplay_song02_02\n",
      "(3567,)\n",
      "coldplay_song07_03\n",
      "(3997,)\n",
      "coldplay_song05_02\n",
      "(3124,)\n",
      "coldplay_song01_05\n",
      "(437,)\n",
      "coldplay_song04_04\n",
      "(588,)\n",
      "coldplay_song06_07\n",
      "(3402,)\n",
      "coldplay_song03_06\n",
      "(5859,)\n",
      "coldplay_song07_01\n",
      "(2591,)\n",
      "coldplay_song06_06\n",
      "(4324,)\n",
      "coldplay_song02_01\n",
      "(7053,)\n",
      "coldplay_song01_04\n",
      "(5510,)\n",
      "coldplay_song04_05\n",
      "(814,)\n",
      "coldplay_song01_01\n",
      "(3969,)\n",
      "coldplay_song07_05\n",
      "(947,)\n",
      "coldplay_song02_04\n",
      "(2207,)\n",
      "coldplay_song06_13\n",
      "(1072,)\n",
      "coldplay_song06_03\n",
      "(3576,)\n",
      "coldplay_song03_02\n",
      "(5983,)\n",
      "coldplay_song07_04\n",
      "(1462,)\n",
      "coldplay_song02_05\n",
      "(1028,)\n",
      "coldplay_song06_02\n",
      "(4785,)\n",
      "coldplay_song06_12\n",
      "(2692,)\n",
      "coldplay_song04_01\n",
      "(5964,)\n",
      "coldplay_song03_01\n",
      "(3200,)\n",
      "coldplay_song06_10\n",
      "(2929,)\n",
      "coldplay_song04_03\n",
      "(1333,)\n",
      "coldplay_song01_02\n",
      "(5983,)\n",
      "coldplay_song06_09\n",
      "(1845,)\n",
      "coldplay_song04_02\n",
      "(4789,)\n",
      "coldplay_song01_03\n",
      "(1571,)\n",
      "coldplay_song06_08\n",
      "(4299,)\n",
      "coldplay_song02_06\n",
      "(2741,)\n",
      "coldplay_song06_01\n",
      "(4984,)\n"
     ]
    }
   ],
   "source": [
    "### Save npy files as required\n",
    "creat_folder('npy')  \n",
    "for i in range(len(csvList)):\n",
    "  lab_name = csvList[i].split('/')[-1].split('.csv')[0]\n",
    "  creat_folder('./npy/'+lab_name)\n",
    "  print(lab_name.strip(\".json.txt\"))\n",
    "#   creat_folder('./npy/'+lab_name+'/current')\n",
    "#   creat_folder('./npy/'+lab_name+'/next')\n",
    "#   creat_folder('./npy/'+lab_name+'/before')\n",
    "#   creat_folder('./npy/'+lab_name+'/corase_encoding')\n",
    "  print(unfolded_df_list[i]['current'].shape)\n",
    "  np.save('./npy/'+lab_name+'/current.npy', unfolded_df_list[i]['current'])\n",
    "  np.save('./npy/'+lab_name+'/next.npy', unfolded_df_list[i]['next'])\n",
    "  np.save('./npy/'+lab_name+'/before.npy', unfolded_df_list[i]['before'])\n",
    "  np.save('./npy/'+lab_name+'/corase_encoding.npy', unfolded_df_list[i]['coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of loading a noy file\n",
    "np_array_example = np.load('./npy/nitech_jp_song070_f001_010.lab/current.npy')\n",
    "np.array(np_array_example.tolist()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the requirement changed, the functions below are not useful anymore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the unfolded dataframe to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a folder under /mono/csv/ called /unfolded/ will becreated which holds all datafames like above\n",
    "try:\n",
    "  # create dictionary to hold all the unfolded file \n",
    "  os.mkdir(label_path + 'csv/unfolded/');\n",
    "  print('unfolded folder created')\n",
    "except:\n",
    "  print('folder already exist')\n",
    "  pass\n",
    "for i in range(len(csvList)):\n",
    "  unfolded_df_list[i].to_csv(label_path + 'csv/unfolded/'+ csvList[i].split('/')[-1], sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After you created all the files, you can load them back to memory easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTICE, if you already have all the files saved, the code below is the only thing you need to load the file and start to work with your training. The code before is only for generating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the path we just created\n",
    "unfolded_path = label_path + 'csv/unfolded/'\n",
    "# get all csv files \n",
    "fileNameList = [unfolded_path + f for f in os.listdir(unfolded_path) if f.endswith('.csv')]\n",
    "unfolded_df_list_ = list()\n",
    "## add all csv files as dataframe to a list\n",
    "for file in fileNameList:\n",
    "  df = pd.read_csv(file, sep='\\t')\n",
    "  unfolded_df_list_.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_df_list_[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### of course you may also want the filename of this specify dataframe to match with raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index of fileNameList maintains the same with unfolded_df_list_\n",
    "fileNameList[0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get one-hot-vector, call phone_to_one_hot() to a specific phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_hot = phone_to_one_hot('sil', phone_dict)\n",
    "print('sil', one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to access one specifiy position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the first dataframe in the list, the index 0, and the current label\n",
    "unfolded_df_list_[0].iloc[0]['current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
